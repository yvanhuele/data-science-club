{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nim is two-player game starting with some number of piles of stones.\n",
    "Each turn, the given player takes any (positive) number of stones from a chosen pile,\n",
    "and the game is finished when no stones are left.\n",
    "\n",
    "In normal play, the player who takes the last stone is the winner.\n",
    "\n",
    "In 'misere' play, the player who takes the last stone is the loser.\n",
    "\n",
    "Note:  Perfect play is not yet implemented for misere play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(a_dict, random = True):\n",
    "    if len(a_dict) == 0:\n",
    "        raise ValueError(\"Trying to find argmax of empty dict\")\n",
    "    max_value = max(a_dict.values())\n",
    "    max_keys = [key for key in a_dict.keys() if a_dict[key] == max_value]\n",
    "    if len(max_keys) >= 2 and random:\n",
    "        return sample(max_keys)\n",
    "    else:\n",
    "        return max_keys[0]\n",
    "\n",
    "def sample(A):\n",
    "    return A[np.random.randint(len(A))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class nim_state:\n",
    "    def __init__(self,v, misere = False):        \n",
    "        self.v = np.array(v).astype(int)\n",
    "        self.num_piles = len(v)\n",
    "        self.player = 0\n",
    "        self.action_space = self.get_action_space()\n",
    "        self.done = False\n",
    "        self.misere = misere\n",
    "        \n",
    "    def get_action_space(self):\n",
    "        actions = []\n",
    "        for j in range(self.num_piles):\n",
    "            for i in range(int(self.v[j])):\n",
    "                action = np.zeros(self.num_piles)\n",
    "                action[j] = i - self.v[j]\n",
    "                actions.append(action)\n",
    "        return actions\n",
    "    \n",
    "    def get_action_from_int(self, i):\n",
    "        partial_sum = 0\n",
    "        for j in range(len(self.v)):\n",
    "            if i < partial_sum + self.v[j]:\n",
    "                    action = np.zeros(self.num_piles)\n",
    "                    action[j] =  i - partial_sum - self.v[j]\n",
    "                    return action\n",
    "            else:\n",
    "                partial_sum += self.v[j]\n",
    "        else:\n",
    "            raise ValueError(\"This action not allowed\")\n",
    "            \n",
    "#     def simulate_step(self, i):\n",
    "#         #returns next state without updating current state\n",
    "#         action = self.get_action_from_int(i)\n",
    "#         next_v = self.v + action\n",
    "#         if any(next_v < 0):\n",
    "#             raise ValueError(\"This action not allowed\")\n",
    "#         else:\n",
    "#             next_state = nim_state(next_v.astype(int))\n",
    "#             next_state.player = 1 - self.player\n",
    "#             return next_state\n",
    "        \n",
    "    \n",
    "    def take_action(self, action, inplace = True):\n",
    "        next_v = self.v + action\n",
    "        if any(next_v < 0):\n",
    "            raise ValueError(\"This action not allowed\")\n",
    "        else:\n",
    "            if inplace:\n",
    "                self.v = next_v.astype(int)\n",
    "                self.player =  1 - self.player\n",
    "            else:\n",
    "                new_state = deepcopy(self)\n",
    "                new_state.v = next_v.astype(int)\n",
    "                new_state.player =  1 - self.player\n",
    "                return new_state\n",
    "                \n",
    "            #self.action_space = self.get_action_from_int()\n",
    "            \n",
    "    def is_done(self):\n",
    "        return all(self.v == np.zeros(self.num_piles))\n",
    "    \n",
    "    def reward(self):\n",
    "        done = self.is_done()\n",
    "        if done and self.player == 0:\n",
    "            reward = 0 #player 1 win\n",
    "        elif done and self.player == 1:\n",
    "            reward = 1  #player 0 win\n",
    "        else:\n",
    "            reward = 0\n",
    "        return reward\n",
    "\n",
    "    def winner(self):\n",
    "        done = self.is_done()\n",
    "        if done and self.player == 0:\n",
    "            winner = 1\n",
    "        elif done and self.player == 1:\n",
    "            winner = 0\n",
    "        else:\n",
    "            winner = None\n",
    "            \n",
    "        if self.misere:\n",
    "            return 1 - winner\n",
    "        return winner\n",
    "\n",
    "    \n",
    "            \n",
    "    def step(self, i, inplace = True):\n",
    "        #self.take_action(self.action_space[i])\n",
    "        if inplace:\n",
    "            self.take_action(self.get_action_from_int(i), inplace = True)\n",
    "            observation = self.v\n",
    "            done = all(self.v == np.zeros(self.num_piles))\n",
    "            self.done = done\n",
    "\n",
    "\n",
    "            #self.reward = reward\n",
    "            reward = self.reward()\n",
    "            info = None\n",
    "            return observation, reward, done, info\n",
    "        else:\n",
    "            new_state = self.take_action(self.get_action_from_int(i), inplace = False)\n",
    "            observation = new_state.v\n",
    "            done = all(new_state.v == np.zeros(new_state.num_piles))\n",
    "            new_state.done = done\n",
    "\n",
    "\n",
    "            #self.reward = reward\n",
    "            reward = new_state.reward()\n",
    "            info = None\n",
    "            return observation, reward, done, info, new_state\n",
    "    \n",
    "    def perfect_action(self):\n",
    "        self.action_space = self.get_action_space()\n",
    "        for i in range(len(self.action_space)):\n",
    "            if reduce(lambda x,y: x ^ y, [int(coord) for coord in self.v + self.action_space[i]] )  == 0:\n",
    "                return i\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def random_action(self):\n",
    "        return np.random.randint(sum(self.v))\n",
    "    \n",
    "    def num_actions(self):\n",
    "        return sum(self.v)\n",
    "    \n",
    "    def perfect_play_winner(self):\n",
    "        current_state_is_won = int(reduce(lambda x,y: x ^ y, game.v)  == 0)\n",
    "        if self.player == 0:\n",
    "            return current_state_is_won\n",
    "        elif self.player == 1:\n",
    "            return 1 - current_state_is_won"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nim is a *solved game*.  That is, the strategy for optimal play is known and easily found at every step.  Here is a game simulated for optimal play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner with perfect play: Player 0\n",
      "state: [1000 1000 1000] to play: 0\n",
      "state: [   0 1000 1000] to play: 1\n",
      "state: [   0  465 1000] to play: 0\n",
      "state: [  0 465 465] to play: 1\n",
      "state: [  0 465   6] to play: 0\n",
      "state: [0 6 6] to play: 1\n",
      "state: [0 6 1] to play: 0\n",
      "state: [0 1 1] to play: 1\n",
      "state: [0 1 0] to play: 0\n",
      "state: [0 0 0] to play: 1\n",
      "Player 0 wins!\n"
     ]
    }
   ],
   "source": [
    "v = [1000,1000,1000]\n",
    "print 'Winner with perfect play: Player', int(reduce(lambda x,y: x ^ y, v)  == 0)\n",
    "env = nim_state(v)\n",
    "observation = env.v\n",
    "print 'state:', observation, 'to play: %d' % env.player\n",
    "for i in range(sum(v)):\n",
    "    action = env.perfect_action()\n",
    "    if action is None:\n",
    "        action = env.random_action()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print 'state:', observation, 'to play: %d' % env.player\n",
    "    if done:\n",
    "        print 'Player %d wins!' % env.winner()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MonteCarloTree:\n",
    "    def __init__(self, game_state, budget = 100, c = 1, twoplayer = True, log_tree_building = False):\n",
    "        \n",
    "        self.root = Node(game_state, index = 0)\n",
    "        self.budget = budget\n",
    "        self.tree = {0:self.root}  #tree is a dictionary of Nodes\n",
    "        self.max_steps = 100\n",
    "        self.c = 1\n",
    "        self.twoplayer = twoplayer\n",
    "        self.log_tree_building = log_tree_building\n",
    "        \n",
    "\n",
    "    def UCTSearch(self):      \n",
    "        nsteps = 1\n",
    "        while nsteps < self.budget:\n",
    "            nsteps += 1\n",
    "            next_node = self.TreePolicy()  #creates a new node and adds to tree\n",
    "\n",
    "            \n",
    "            if self.root.is_complete and self.root.is_won:\n",
    "                #if self.log_tree_building:\n",
    "                print \"Found winning move.\"\n",
    "                break\n",
    "            elif self.root.is_complete and not self.root.is_won:\n",
    "                #if self.log_tree_building:\n",
    "                print \"Guaranteed loss! Returning None.\"\n",
    "                return None\n",
    "            else:\n",
    "                Q = self.Simulate(next_node)\n",
    "                self.BackPropogate(next_node, Q)\n",
    "        return self.BestChild(self.root, explore = False).action\n",
    "        \n",
    "    def TreePolicy(self):\n",
    "        node = self.root\n",
    "        while len(node.children) > 0:  #explore until a leaf is found\n",
    "            if len(node.children) < node.state.num_actions(): #if not fully expanded\n",
    "                return self.Expand(node)\n",
    "            else:\n",
    "                node = self.BestChild(node, self.c)\n",
    "        return self.Expand(node)\n",
    "                \n",
    "    def Simulate(self,node):\n",
    "        \n",
    "        if node.state.is_done():\n",
    "#             if node.state.reward() > 0:  ### assuming for now reward >0 means 'won game'\n",
    "#                 reward = np.inf\n",
    "#             else:\n",
    "#                 reward = node.state.reward()\n",
    "            reward = node.state.reward()\n",
    "            if reward is None:\n",
    "                raise ValueError('eh?', node.state.v)\n",
    "            return reward\n",
    "        else:\n",
    "            nsteps = 0\n",
    "            current_state = deepcopy(node.state)\n",
    "            #Should we be updating the tree here?\n",
    "            while nsteps < self.max_steps:\n",
    "                action = current_state.random_action()\n",
    "                observation, reward, done, info = current_state.step(action)\n",
    "                if done:\n",
    "                    return reward\n",
    "            else:\n",
    "                raise ValueError(\"Max number of steps exceeded\")\n",
    "    \n",
    "    def Expand(self,node):\n",
    "        if len(node.children) >= node.state.num_actions():\n",
    "            raise ValueError(\"Node fully expanded already\")\n",
    "        else:\n",
    "            action = len(node.children)\n",
    "            new_index = max(self.tree.keys()) + 1\n",
    "            if self.log_tree_building:\n",
    "                print \"Adding node %d from parent %d with action %d\" % (new_index, node.index, action)\n",
    "            observation, reward, done, info, new_state = node.state.step(action, inplace = False)\n",
    "            new_child = Node(new_state, new_index, action = action, parent = node.index)\n",
    "            node.children.append(new_index)\n",
    "            self.tree[new_index] = new_child\n",
    "              \n",
    "            self.BackPropogate_EndGame(new_index)\n",
    "                            \n",
    "            return new_child\n",
    "            \n",
    "            \n",
    "    def BackPropogate_EndGame(self, index):\n",
    "        node = self.tree[index]\n",
    "        \n",
    "        if self.twoplayer:\n",
    "            if node.state.done:\n",
    "                node.is_complete = True\n",
    "                if node.state.winner == node.state.player:\n",
    "                    node.is_won = True\n",
    "                else:\n",
    "                    node.is_won = False\n",
    "                \n",
    "\n",
    "            \n",
    "            elif any([self.tree[child_index].is_complete and not self.tree[child_index].is_won for child_index in node.children]):\n",
    "                #if any child is a loss to that player, the current node is a WIN for the current player.\n",
    "                self.tree[index].is_complete = True\n",
    "                self.tree[index].is_won = True\n",
    "\n",
    "            elif len(node.children) >= node.state.num_actions(): #fully expanded\n",
    "                if all([self.tree[child_index].is_complete and self.tree[child_index].is_won for child_index in node.children]):\n",
    "                    self.tree[index].is_complete = True\n",
    "                    self.tree[index].is_won = False\n",
    "        else:\n",
    "            #single-player game\n",
    "            if node.state.done:\n",
    "                node.is_complete = True\n",
    "                if node.state.winner == node.state.player:\n",
    "                    node.is_won = True\n",
    "                else:\n",
    "                    node.is_won = False\n",
    "            elif any([self.tree[child_index].is_complete and not self.tree[child_index].is_won for child_index in node.children]):\n",
    "                #if any child is a win, the current node is a win for the current player.\n",
    "                self.tree[index].is_complete = True\n",
    "                self.tree[index].is_won = True\n",
    "            elif len(node.children) >= node.state.num_actions(): #fully expanded\n",
    "                if all([self.tree[child_index].is_complete and not self.tree[child_index].is_won for child_index in node.children]):\n",
    "                    #if ALL children are losses the the current node is a loss.                    \n",
    "                    self.tree[index].is_complete = True\n",
    "                    self.tree[index].is_won = False\n",
    "                    \n",
    "        \n",
    "        if node.is_complete:\n",
    "            if node.is_won:\n",
    "                end_string = 'win'\n",
    "            else:\n",
    "                end_string = 'loss'\n",
    "            if self.log_tree_building:\n",
    "                print \"Node %d is complete and is a %s!!\" % (node.index, end_string)\n",
    "            \n",
    "            if not node.parent is None:\n",
    "                self.BackPropogate_EndGame(node.parent)\n",
    "\n",
    "\n",
    "    \n",
    "    def BackPropogate(self, node, reward):\n",
    "        node_index = node.index\n",
    "        while not node_index is None:\n",
    "            node = self.tree[node_index]\n",
    "            node.Q += reward\n",
    "            node.N += 1\n",
    "            if self.twoplayer:\n",
    "                reward = -reward\n",
    "            node_index = node.parent\n",
    "    \n",
    "    def BestChild(self, node, explore = True):\n",
    "        #Perform Sophie's Choice\n",
    "        if len(node.children) == 0:\n",
    "            raise ValueError(\"Node has no children\")\n",
    "        if explore and node.is_complete:\n",
    "            raise ValueError(\"Node has already been fully explored\")\n",
    "        \n",
    "        S = {}\n",
    "        \n",
    "        for i in node.children:\n",
    "            child = self.tree[i]\n",
    "            if self.twoplayer:\n",
    "                if child.is_complete and child.is_won:\n",
    "                    #this child is a loss to the current node's player.  No need to investigate further.\n",
    "                    continue\n",
    "                if child.is_complete and child.is_won == False:\n",
    "                    #this child is a WIN to the current node's player.  Take this move and don't explore further.\n",
    "                    return child\n",
    "            else:\n",
    "                raise ValueError(\"not implemented\")\n",
    "\n",
    "\n",
    "            if explore:\n",
    "\n",
    "                    if child.N == 0:\n",
    "                        S[i] = np.inf\n",
    "                    else:\n",
    "                        S[i] = child.Q / child.N + self.c * np.sqrt(  2 * np.log( node.N ) / child.N  )\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    S[i] = child.Q / child.N\n",
    "                except:\n",
    "                    raise ValueError(\"Node %d has N = 0\" % i)\n",
    "        child = self.tree[argmax(S)]  #should we return an INDEX?\n",
    "        return child\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, index, action = None, parent = None):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.children = []\n",
    "        self.index = index\n",
    "        self.parent = parent\n",
    "        self.Q = 0  #total reward\n",
    "        self.N = 0  #total visit count\n",
    "        self.is_complete = False # Set to True if subtree with this root is FULLY expanded to endgame\n",
    "        self.is_won = None #Set to True if game is a win for the CURRENT player, \n",
    "                           #False if game is a loss for the CURRENT player, otherwise None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 0 now choosing action from state [5 5].  Perfect play winner: 1.\n",
      "Size of tree: 100\n",
      "\n",
      "Player 1 now choosing action from state [5 2].  Perfect play winner: 1.\n",
      "Size of tree: 100\n",
      "\n",
      "Player 0 now choosing action from state [2 2].  Perfect play winner: 1.\n",
      "Guaranteed loss! Returning None.\n",
      "Size of tree: 25\n",
      "No good move.  Taking random action.\n",
      "\n",
      "Player 1 now choosing action from state [1 2].  Perfect play winner: 1.\n",
      "Found winning move.\n",
      "Size of tree: 10\n",
      "\n",
      "Player 0 now choosing action from state [1 1].  Perfect play winner: 1.\n",
      "Guaranteed loss! Returning None.\n",
      "Size of tree: 5\n",
      "No good move.  Taking random action.\n",
      "\n",
      "Player 1 now choosing action from state [0 1].  Perfect play winner: 1.\n",
      "Found winning move.\n",
      "Size of tree: 2\n",
      "\n",
      "Player 0 now choosing action from state [0 0].  Perfect play winner: 1.\n",
      "Player 1 wins!\n"
     ]
    }
   ],
   "source": [
    "v = [5,5]\n",
    "\n",
    "misere = False\n",
    "\n",
    "game = nim_state(v, misere = misere)\n",
    "print 'Player %d now choosing action from state %s.  Perfect play winner: %d.' % (game.player, game.v, game.perfect_play_winner())    \n",
    "for i in range(100):\n",
    "    game_tree = MonteCarloTree( nim_state(game.v, misere = misere), budget = 100)\n",
    "    action = game_tree.UCTSearch()\n",
    "    print 'Size of tree: %d' % len(game_tree.tree)\n",
    "\n",
    "    if action is None:\n",
    "        print \"No good move.  Taking random action.\"\n",
    "        action = game.random_action()\n",
    "    (observation, reward, done, info) = game.step(action)\n",
    "    print ''\n",
    "    print 'Player %d now choosing action from state %s.  Perfect play winner: %d.' % (game.player, game.v, game.perfect_play_winner())    \n",
    "    \n",
    "    if done:\n",
    "        print 'Player %d wins!' % game.winner()\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
