{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy \n",
    "from IPython.html.widgets import interact\n",
    "from IPython.html.widgets import IntSlider\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class checkers_state:\n",
    "    def __init__(self,board_size = 8, verbose = False, notes = None, allow_kings = True, allow_draws = False, max_turns = 100):        \n",
    "        self.board_size = board_size\n",
    "        self.board = self.create_board(n = board_size)\n",
    "        self.player = 0\n",
    "        #self.action_space = self.get_action_space()\n",
    "        self.done = False\n",
    "        self.num_just_jumped = 0\n",
    "        self.update_action_space()\n",
    "        self.verbose = verbose\n",
    "        self.notes = None\n",
    "        self.max_turns = max_turns\n",
    "        self.turn_num = 0 ##Total number of turns moved thus far\n",
    "        self.allow_draws = allow_draws\n",
    "        \n",
    "    def create_board(self, n):\n",
    "        board = np.zeros([n,n]).astype(int)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i < n/2 - 1:\n",
    "                    x = 1\n",
    "                elif (n-i) < n/2:\n",
    "                    x = -1\n",
    "                else:\n",
    "                    continue\n",
    "                if (i + j) % 2 == 1:\n",
    "                    board[j,i] = x\n",
    "        return board    \n",
    "    \n",
    "    \n",
    "    def show_board(self):\n",
    "        #plt.clf()\n",
    "        rcParams['figure.figsize'] = 4,4\n",
    "        #fig, ax = plt.subplots() # note we must use plt.subplots, not plt.subplot\n",
    "        # (or if you have an existing figure)\n",
    "        # fig = plt.gcf()\n",
    "        # ax = fig.gca()\n",
    "\n",
    "        #ax.add_artist(circle2)\n",
    "        fig, ax = plt.subplots() \n",
    "\n",
    "        #ax.add_artist(plt.Circle( (i + .5, j + .5), 0.2, color='blue'))\n",
    "\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if (i + j) % 2 == 0:\n",
    "                    square_color = 'grey'\n",
    "                else:\n",
    "                    square_color = 'white'\n",
    "\n",
    "                ax.add_artist(plt.Rectangle( (i, j), 1,1, color=square_color))\n",
    "                if self.board[i,j] > 0:\n",
    "                    color = 'red'\n",
    "                elif self.board[i,j] < 0:\n",
    "                    color = 'black'\n",
    "                else:\n",
    "                    continue\n",
    "                #print i,j\n",
    "                ax.add_artist(plt.Circle( (i + .5, j + .5), 0.2, color=color))\n",
    "                if abs(self.board[i,j]) > 1:\n",
    "                    ###This piece is a king\n",
    "                    ax.add_artist(plt.Circle( (i + .5, j + .5), 0.3, color=color, fill = False))\n",
    "\n",
    "        plt.xlim(0,self.board_size)\n",
    "        plt.ylim(0,self.board_size)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def player_pieces(self, player = None):\n",
    "        if player is None:\n",
    "            player = self.player\n",
    "        pieces = []\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if player == 0 and self.board[i,j] > 0:\n",
    "                    pieces.append((i,j))\n",
    "                if player == 1 and self.board[i,j] < 0:\n",
    "                    pieces.append((i,j))\n",
    "        return pieces\n",
    "                \n",
    "            \n",
    "    def get_action_space(self):\n",
    "        return self.action_space\n",
    "    \n",
    "    def update_action_space(self):\n",
    "        possible_jumps = []\n",
    "        possible_moves = []\n",
    "        \n",
    "        if self.num_just_jumped > 0:\n",
    "            pieces_to_move = [self.last_jumper]\n",
    "        else:\n",
    "            pieces_to_move = self.player_pieces()\n",
    "        \n",
    "        for u in pieces_to_move:\n",
    "            for move_vector in self.legal_vectors(u):\n",
    "                v = (u[0] + move_vector[0], u[1] + move_vector[1])\n",
    "                action = (u,v)\n",
    "                if self.is_legal(action):\n",
    "                    possible_moves.append(action)\n",
    "                    if np.abs(move_vector[0]) > 1:\n",
    "                        possible_jumps.append(action)\n",
    "        \n",
    "        if len(possible_jumps) > 0:\n",
    "            #if you can jump, you must jump\n",
    "            self.must_jump = True\n",
    "            if self.verbose:\n",
    "                print \"MUST JUMP!!, possible jumps:\", possible_jumps\n",
    "            self.action_space = possible_jumps\n",
    "        else:\n",
    "            self.must_jump = False\n",
    "            self.action_space =  possible_moves\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_action_from_int(self, i):\n",
    "        if i > self.num_actions():\n",
    "            raise ValueError(\"Action index %d not in range of action space of length %d\" % (i, self.num_actions()))\n",
    "        else:\n",
    "            return self.action_space[i]\n",
    "            \n",
    "            \n",
    "    def is_legal(self, action, explain = False):\n",
    "        legal = True\n",
    "        (u,v) = action\n",
    "        #print 'Checking action', action\n",
    "        if not all([0 <= u[i] < self.board_size for i in range(2)]):\n",
    "            if explain:\n",
    "                print \"Player %d trying to move a piece not in range (0, %d)\" % (self.player, self.board_size) \n",
    "            return False\n",
    "        elif not all([0 <= v[i] < self.board_size for i in range(2)]):\n",
    "            if explain:\n",
    "                print \"Player %d trying to move a piece to outside of (0, %d)\" % (self.player, self.board_size) \n",
    "            return False\n",
    "        \n",
    "        if self.board[u] == 0:\n",
    "            if explain:\n",
    "                print \"Player %d is trying to move from empty position (%d,%d)\" % (self.player, u[0], u[1])\n",
    "\n",
    "            return False\n",
    "        elif self.board[v] != 0:\n",
    "            if explain:\n",
    "                print \"Player %d is trying to move to nonempty position (%d,%d)\" % (self.player, v[0], v[1])\n",
    "\n",
    "            return False\n",
    "        elif (self.board[u] > 0 and self.player == 1) or (self.board[u] > 0 and self.player == 1):\n",
    "            if explain:\n",
    "                print \"Player %d trying to move a piece belonging to player %d\" % (self.player, 1 - self.player)\n",
    "\n",
    "            return False\n",
    "        \n",
    "\n",
    "            \n",
    "        move_vector =  (v[0] - u[0], v[1] - u[1])   \n",
    "        \n",
    "        if not move_vector in self.legal_vectors(u):\n",
    "            if explain:\n",
    "                print \"Player %d trying vector %s, not in legal vectors %s\" % (self.player, move_vector, self.legal_vectors(u))\n",
    "\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        if np.abs(move_vector[0]) > 1:\n",
    "            \n",
    "            w = (int((u[0] + v[0]) / 2), int((u[1] + v[1]) / 2))\n",
    "            \n",
    "            if self.player == 0 and self.board[w] < 0:\n",
    "                pass\n",
    "                #print \"Jumped piece at position (%d,%d)\" % w\n",
    "            elif self.player == 1 and self.board[w] > 0:\n",
    "                pass\n",
    "                #print \"Jumped piece at position (%d,%d)\" % w\n",
    "            else:\n",
    "                if explain:\n",
    "                    print \"Player %d trying to jump own piece or empty position at %s\" (self.player, w)\n",
    "                return False        \n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def legal_vectors(self, piece):\n",
    "        if np.abs(self.board[piece]) > 1:\n",
    "            #this piece is a king\n",
    "            legal_vectors = [(1,1), (-1,1), (2,2), (-2, 2), (1,-1), (-1,-1), (2,-2), (-2, -2)]\n",
    "        elif self.player == 0:\n",
    "            legal_vectors =  [(1,1), (-1,1), (2,2), (-2, 2)]\n",
    "        elif self.player == 1:\n",
    "            legal_vectors = [(1,-1), (-1,-1), (2,-2), (-2, -2)]\n",
    "            \n",
    "        return legal_vectors\n",
    "    \n",
    "    def take_action(self, action, inplace = True):\n",
    "        \n",
    "        # an action is a tuple of two (u,v) where u,v are 2x2 vectors;\n",
    "        # u coordinates of a checker, v coordinates of a place to move to\n",
    "        \n",
    "        (u,v) = action\n",
    "        \n",
    "        #player = 0 -> positive pieces\n",
    "        #player = 1 -> negative pieces\n",
    "        \n",
    "        if not all([0 <= u[i] < self.board_size for i in range(2)]):\n",
    "            raise ValueError(\"Player %d trying to move a piece not in range (0, %d)\" % (self.player, self.board_size) )\n",
    "        if not all([0 <= v[i] < self.board_size for i in range(2)]):\n",
    "            raise ValueError(\"Player %d trying to move a piece to outside of (0, %d)\" % (self.player, self.board_size) )\n",
    "        if self.board[u] == 0:\n",
    "            raise ValueError(\"Player %d is trying to move from empty position (%d,%d)\" % (self.player, u[0], u[1]) )\n",
    "        elif self.board[v] != 0:\n",
    "            raise ValueError(\"Player %d is trying to move to nonempty position (%d,%d)\" % (self.player, v[0], v[1]))\n",
    "        elif (self.board[u] > 0 and self.player == 1) or (self.board[u] > 0 and self.player == 1):\n",
    "            raise ValueError(\"Player %d trying to move a piece belonging to player %d\" % (self.player, 1 - self.player))\n",
    "        \n",
    "        if inplace:\n",
    "            next_state = self\n",
    "        else:\n",
    "            next_state = deepcopy(self)\n",
    "        \n",
    "        if abs(u[0] - v[0]) == 2:\n",
    "            w = (int((u[0] + v[0]) / 2), int((u[1] + v[1]) / 2))\n",
    "            if (self.player == 0 and self.board[w] < 0) or (self.player == 1 and self.board[w] > 0):\n",
    "                next_state.board[w] = 0\n",
    "                if self.verbose:\n",
    "                    print \"Jumped piece at position (%d,%d)\" % w\n",
    "                next_state.num_just_jumped += 1\n",
    "            else:\n",
    "                raise ValueError(\"Trying to jump own piece or empty position at %s\", w)\n",
    "        \n",
    "        \n",
    "        next_state.board[v] = next_state.board[u]\n",
    "        next_state.board[u] = 0\n",
    "        if np.abs(next_state.board[v]) == 1:\n",
    "            if (next_state.player == 0 and v[1] == next_state.board_size - 1) or (next_state.player == 1 and v[1] == 0):\n",
    "                if self.verbose:\n",
    "                    print \"King me!\"\n",
    "                next_state.board[v] = next_state.board[v] * 2\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        if next_state.num_just_jumped > 0:\n",
    "            next_state.last_jumper = v\n",
    "            next_state.update_action_space()\n",
    "            if next_state.must_jump:\n",
    "                if self.verbose:\n",
    "                    adj_dict = {2:'DOUBLE', 3:'TRIPLE', 4:'QUADRUPLE', 5:'QUINTUPLE'}\n",
    "\n",
    "                    print \"%s JUMP!!\" % (adj_dict[next_state.num_just_jumped + 1])\n",
    "                    pass\n",
    "            else:\n",
    "                next_state.switch_players()\n",
    "        else:\n",
    "            next_state.switch_players()\n",
    "        next_state.update_action_space()\n",
    "        \n",
    "        next_state.turn_num += 1\n",
    "        \n",
    "        if inplace:\n",
    "            return None\n",
    "        else:\n",
    "            return next_state\n",
    "        \n",
    "\n",
    "            #self.action_space = self.get_action_from_int()\n",
    "            \n",
    "    def switch_players(self):\n",
    "        self.player = (1 - self.player)\n",
    "        self.num_just_jumped = 0\n",
    "        self.must_jump = False\n",
    "        self.update_action_space()\n",
    "        self.last_jumper = None\n",
    "\n",
    "            \n",
    "    def is_done(self):\n",
    "        return (len(self.action_space) == 0) or self.turn_num >= self.max_turns\n",
    "    \n",
    "    def reward(self):\n",
    "        reward = 0\n",
    "        done = self.is_done()\n",
    "        if done:\n",
    "            if self.winner() == self.player:\n",
    "                reward = 1\n",
    "        return reward\n",
    "\n",
    "    def winner(self):\n",
    "        done = self.is_done()\n",
    "        \n",
    "        if done:\n",
    "\n",
    "            player_0_pieces = self.player_pieces(player = 0)\n",
    "            player_1_pieces = self.player_pieces(player = 1)\n",
    "            if len(player_0_pieces) > len(player_1_pieces):\n",
    "                return 0\n",
    "            elif len(player_1_pieces) > len(player_0_pieces):\n",
    "                return 1\n",
    "            else:\n",
    "                ###DRAW###x\n",
    "                if self.allow_draws:\n",
    "                    return 'draw'\n",
    "                else:\n",
    "                    return 0 \n",
    "                    ##Player 0 wins draws, just cause.##\n",
    " \n",
    "            \n",
    "    def step(self, i, inplace = True):\n",
    "        #self.take_action(self.action_space[i])\n",
    "#         if not inplace:\n",
    "#             orig_board = deepcopy(self.board)\n",
    "        \n",
    "        if inplace:\n",
    "            self.take_action(self.get_action_from_int(i), inplace = True)\n",
    "            next_state = self\n",
    "        else:\n",
    "            next_state = self.take_action(self.get_action_from_int(i), inplace = False)\n",
    "            \n",
    "        observation = next_state.board\n",
    "        #done = len(next_state.action_space) == 0\n",
    "        done = next_state.is_done()\n",
    "        next_state.done = done\n",
    "\n",
    "\n",
    "        #self.reward = reward\n",
    "        reward = self.reward()\n",
    "        info = None\n",
    "#         if not inplace:\n",
    "#             if (self.board == orig_board).all():\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 print \"WTF?\"\n",
    "#                 raise ValueError(\"not inplace but changing state\")\n",
    "        \n",
    "        \n",
    "        if inplace:\n",
    "            return observation, reward, done, info\n",
    "        else:\n",
    "            return observation, reward, done, info, next_state\n",
    "\n",
    "    \n",
    "        \n",
    "    def step_random(self, inplace = True):\n",
    "        return self.step(self.random_action(), inplace = inplace)\n",
    "    \n",
    "    def random_action(self):\n",
    "        k = self.num_actions()\n",
    "        #print 'choosing from %d actions.' % k\n",
    "        return np.random.randint(k)\n",
    "    \n",
    "    def num_actions(self):\n",
    "        return len(self.action_space)\n",
    "    \n",
    "def argmax(a_dict, random = True):\n",
    "    if len(a_dict) == 0:\n",
    "        raise ValueError(\"Trying to find argmax of empty dict\")\n",
    "    max_value = max(a_dict.values())\n",
    "    max_keys = [key for key in a_dict.keys() if a_dict[key] == max_value]\n",
    "    \n",
    "    if len(max_keys) == 0:\n",
    "        raise ValueError(\"Cannot choose max argmax for dict\", a_dict)\n",
    "    elif len(max_keys) >= 2 and random:\n",
    "        return sample(max_keys)\n",
    "    else:\n",
    "        return sorted(max_keys)[0]\n",
    "\n",
    "def sample(A):\n",
    "    return A[np.random.randint(len(A))]\n",
    "\n",
    "def refactor(df, columns, preserved  = []):\n",
    "    groups = [group.rename_axis({col:col + '_%s' % (str(x)) for col in group.columns if not col in preserved + columns }, axis = 'columns').reset_index() for x,group in df.groupby(columns)]\n",
    "    for i in range(len(groups)):\n",
    "        groups[i]['index'] = 0\n",
    "        groups[i] = groups[i][[col for col in groups[i].columns if not col in columns]]\n",
    "    df_refactored =  reduce( lambda df1, df2:  df1.merge(df2, how = 'outer'), groups)\n",
    "    del df_refactored['index']\n",
    "    return df_refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MonteCarloTree:\n",
    "    def __init__(self, game_state, \n",
    "                 budget = 100, \n",
    "                 c = 1, \n",
    "                 twoplayer = True, \n",
    "                 log_tree_building = False, \n",
    "                 num_simulations = 1,\n",
    "                 endgame_predictor = None,\n",
    "                 max_steps_to_simulate = 100):\n",
    "        \n",
    "        self.root = Node(game_state, index = 0)\n",
    "        self.budget = budget\n",
    "        self.tree = {0:self.root}  #tree is a dictionary of Nodes\n",
    "        self.max_steps_to_simulate = max_steps_to_simulate\n",
    "        self.c = 1\n",
    "        self.twoplayer = twoplayer\n",
    "        self.log_tree_building = log_tree_building\n",
    "        self.root_player = game_state.player\n",
    "        self.num_simulations = num_simulations\n",
    "        self.endgame_predictor = endgame_predictor\n",
    "\n",
    "    def UCTSearch(self): \n",
    "        \n",
    "        if self.budget == 0:\n",
    "            #If budget is 0, return random move.\n",
    "            return self.root.state.random_action()\n",
    "        \n",
    "        self.root.N = 1\n",
    "        nsteps = 0\n",
    "        while nsteps < self.budget:\n",
    "            nsteps += 1\n",
    "            next_node = self.TreePolicy()  #creates a new node and adds to tree\n",
    "\n",
    "            \n",
    "            if self.root.is_complete and self.root.is_won:\n",
    "                #if self.log_tree_building:\n",
    "                self.root.state.notes += \"Found winning move.\\n\"\n",
    "                if self.log_tree_building:\n",
    "                    print \"Found winning move.\"\n",
    "\n",
    "                break\n",
    "            if self.root.is_complete and not self.root.is_won:\n",
    "                #if self.log_tree_building:\n",
    "                self.root.state.notes += \"Guaranteed loss!\\n\"\n",
    "                if self.log_tree_building:\n",
    "                    print \"Guaranteed loss!\"\n",
    "                break\n",
    "            else:\n",
    "                total_Q = 0\n",
    "                for i in range(self.num_simulations):\n",
    "                    Q = self.Simulate(next_node)\n",
    "                    total_Q += Q\n",
    "                    next_node.all_simulation_results.append(Q)\n",
    "                self.BackPropogate(next_node, total_Q)\n",
    "        return self.BestChild(self.root, explore = False).action\n",
    "\n",
    "    def TreePolicy(self):\n",
    "        node = self.root\n",
    "        while len(node.children) > 0:  #explore until a leaf is found\n",
    "            if len(node.children) < node.state.num_actions(): #if not fully expanded\n",
    "                return self.Expand(node)\n",
    "            else:\n",
    "                node = self.BestChild(node, self.c)\n",
    "        return self.Expand(node)\n",
    "\n",
    "    \n",
    "    def Simulate(self,node):\n",
    "        node.N += 1\n",
    "        step_num = 0\n",
    "        if node.state.is_done():\n",
    "            reward = node.state.reward()\n",
    "            if reward is None:\n",
    "                raise ValueError('eh?', node.state.v)\n",
    "            return reward\n",
    "        else:\n",
    "            nsteps = 0\n",
    "            current_state = deepcopy(node.state)\n",
    "            #Should we be updating the tree here?\n",
    "            while nsteps < self.max_steps_to_simulate:\n",
    "                nsteps += 1\n",
    "                action = current_state.random_action()\n",
    "                observation, reward, done, info = current_state.step(action)\n",
    "                \n",
    "                #ignore given reward.\n",
    "                \n",
    "                if done:\n",
    "                    #Reward is 1 if root player is winner, otherwise 0.\n",
    "                    \n",
    "                    if current_state.winner() == self.root_player:\n",
    "                        reward = 1.0\n",
    "                    else:\n",
    "                        reward = 0.0\n",
    "                    return reward\n",
    "            else:\n",
    "                if self.endgame_predictor is None:\n",
    "                    raise ValueError(\"Max number of steps exceeded\")\n",
    "                else:\n",
    "                    predicted_winner = self.endgame_predictor.predict(current_state)\n",
    "                    return predicted_winner\n",
    "\n",
    "\n",
    "\n",
    "    def Expand(self,node):\n",
    "        if len(node.children) >= node.state.num_actions():\n",
    "            raise ValueError(\"Node fully expanded already\")\n",
    "        else:\n",
    "            action = len(node.children)\n",
    "            new_index = max(self.tree.keys()) + 1\n",
    "            if self.log_tree_building:\n",
    "                print \"Adding node %d from parent %d with action %d\" % (new_index, node.index, action)\n",
    "            observation, reward, done, info, new_state = node.state.step(action, inplace = False)\n",
    "            new_child = Node(new_state, new_index, action = action, parent = node.index)\n",
    "            node.children.append(new_index)\n",
    "            self.tree[new_index] = new_child\n",
    "\n",
    "            self.BackPropogate_EndGame(new_index)\n",
    "\n",
    "            return new_child\n",
    "            \n",
    "            \n",
    "    def BackPropogate_EndGame(self, index):\n",
    "        node = self.tree[index]\n",
    "        \n",
    "        if self.twoplayer:\n",
    "            if node.state.done:\n",
    "                node.is_complete = True\n",
    "                if node.state.winner == node.state.player:\n",
    "                    node.is_won = True\n",
    "                else:\n",
    "                    node.is_won = False\n",
    "                \n",
    "\n",
    "            \n",
    "            elif any([self.tree[child_index].state.player != node.state.player and  self.tree[child_index].is_complete and not self.tree[child_index].is_won for child_index in node.children]):\n",
    "                #if any child is opponent and is a loss to that player, the current node is a WIN for the current player.\n",
    "                self.tree[index].is_complete = True\n",
    "                self.tree[index].is_won = True\n",
    "\n",
    "            elif any([self.tree[child_index].state.player == node.state.player and  self.tree[child_index].is_complete and self.tree[child_index].is_won for child_index in node.children]):\n",
    "                #if any child is current player and a win, the current node is a WIN for the current player.\n",
    "                self.tree[index].is_complete = True\n",
    "                self.tree[index].is_won = True                \n",
    "                \n",
    "            elif len(node.children) >= node.state.num_actions(): #fully expanded\n",
    "                '''\n",
    "                If current node is fully expanded and every child is either \n",
    "                \n",
    "                a) the opponent's turn, and a win\n",
    "                or\n",
    "                b) the current node's player's turn, and a loss\n",
    "                \n",
    "                then, the current node is a loss.\n",
    "                '''\n",
    "                if all([(self.tree[child_index].state.player != node.state.player and self.tree[child_index].is_complete and self.tree[child_index].is_won)  or\n",
    "                        (self.tree[child_index].state.player == node.state.player and self.tree[child_index].is_complete and (not self.tree[child_index].is_won) )\n",
    "                            for child_index in node.children]):\n",
    "                    self.tree[index].is_complete = True\n",
    "                    self.tree[index].is_won = False\n",
    "        else:\n",
    "            #single-player game\n",
    "            if node.state.done:\n",
    "                node.is_complete = True\n",
    "                if node.state.winner == node.state.player:\n",
    "                    node.is_won = True\n",
    "                else:\n",
    "                    node.is_won = False\n",
    "            elif any([self.tree[child_index].is_complete and not self.tree[child_index].is_won for child_index in node.children]):\n",
    "                #if any child is a win, the current node is a win for the current player.\n",
    "                self.tree[index].is_complete = True\n",
    "                self.tree[index].is_won = True\n",
    "            elif len(node.children) >= node.state.num_actions(): #fully expanded\n",
    "                if all([self.tree[child_index].is_complete and not self.tree[child_index].is_won for child_index in node.children]):\n",
    "                    #if ALL children are losses the the current node is a loss.                    \n",
    "                    self.tree[index].is_complete = True\n",
    "                    self.tree[index].is_won = False\n",
    "                    \n",
    "        \n",
    "        if node.is_complete:\n",
    "            if node.is_won:\n",
    "                end_string = 'win'\n",
    "            else:\n",
    "                end_string = 'loss'\n",
    "            if self.log_tree_building:\n",
    "                print \"Node %d is complete and is a %s!!\" % (node.index, end_string)\n",
    "            \n",
    "            if not node.parent is None:\n",
    "                self.BackPropogate_EndGame(node.parent)\n",
    "\n",
    "    def BackPropogate(self, node, reward):\n",
    "        node = deepcopy(node)\n",
    "        node_index = node.index\n",
    "        while not node_index is None:\n",
    "            node = self.tree[node_index]\n",
    "            node.Q += reward\n",
    "            node_index = node.parent\n",
    "    \n",
    "    def BestChild(self, node, explore = True, display_scores = False):\n",
    "        #Perform Sophie's Choice\n",
    "        if len(node.children) == 0:\n",
    "            raise ValueError(\"Node has no children\")\n",
    "        if explore and node.is_complete:\n",
    "            raise ValueError(\"Node has already been fully explored\")\n",
    "        \n",
    "        S = {}\n",
    "        \n",
    "        for i in node.children:\n",
    "            child = self.tree[i]\n",
    "            \n",
    "            ##First, check for any winning moves and take one if possible.\n",
    "            \n",
    "            if self.twoplayer:\n",
    "                if child.state.player != node.state.player:\n",
    "                    if child.is_complete and not child.is_won:\n",
    "                        #this child is a LOSS for the opponent.  Take this move and don't explore further.                            \n",
    "                        return child\n",
    "                elif child.state.player == node.state.player:\n",
    "                    if child.is_complete and child.is_won:  \n",
    "                        #this child is a WIN to the current node's player.  Take this move and don't explore further.\n",
    "                        return child\n",
    "            else:\n",
    "                raise ValueError(\"not implemented\")\n",
    "\n",
    "\n",
    "            if explore:\n",
    "                if child.is_complete:\n",
    "                    #This child completely explored; do not bother.\n",
    "                    continue\n",
    "                \n",
    "                if child.N == 0:\n",
    "                    S[i] = np.inf\n",
    "                else:\n",
    "                    Q = child.Q\n",
    "                    if node.state.player != self.root_player:\n",
    "                        Q = -Q\n",
    "                    S[i] = Q / float(child.N) + self.c * np.sqrt(  2 * np.log( node.N ) / float(child.N)  )\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    Q = child.Q\n",
    "                    if node.state.player != self.root_player:\n",
    "                        Q = -Q\n",
    "                    S[i] = Q / float(child.N)  #Should we bias towards high N for conservative play?\n",
    "                except:\n",
    "                    raise ValueError(\"Node %d has N = 0\" % i)\n",
    "                    \n",
    "        if display_scores:\n",
    "            print S\n",
    "\n",
    "        child = self.tree[argmax(S, random = False)]  #should we return an INDEX?\n",
    "        return child\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, index, action = None, parent = None):\n",
    "        self.state = state\n",
    "        self.action = action  #The action that went from the parent of this state to this state.\n",
    "        self.children = []\n",
    "        self.index = index\n",
    "        self.parent = parent\n",
    "        self.Q = 0  #total reward\n",
    "        self.N = 0  #total visit count\n",
    "        self.is_complete = False # Set to True if subtree with this root is FULLY expanded to endgame\n",
    "        self.is_won = None #Set to True if game is a win for the CURRENT player, \n",
    "                           #False if game is a loss for the CURRENT player, otherwise None\n",
    "        self.all_simulation_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simple_checkers_predictor:\n",
    "    def __init__(self, king_score = 2):\n",
    "        self.scoring_dict = {0:0, 1:1, 2:king_score}\n",
    "\n",
    "    def predict(self, state):\n",
    "        ###Predicts the winner of a checkers game using a simple scoring system.\n",
    "        if state.is_done():\n",
    "            return state.winner()\n",
    "        else:\n",
    "            total_scores = [0,0]\n",
    "\n",
    "            for i in range(state.board_size):\n",
    "                for j in range(state.board_size):\n",
    "                    score = self.scoring_dict[np.abs(state.board[i,j])]\n",
    "                    player = 0 if state.board[i,j] > 0 else 1\n",
    "                    total_scores[player] += score\n",
    "\n",
    "            if total_scores[0] > total_scores[1]:\n",
    "                return 0\n",
    "            elif total_scores[1] > total_scores[0]:\n",
    "                return 1\n",
    "            else:\n",
    "                ##Draw\n",
    "                if state.allow_draws:\n",
    "                    return 'draw'\n",
    "                else:\n",
    "                    return 0 #Player 0 wins draws, just 'cuz.\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game played with pre-determined moves to test rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# B = checkers_state(board_size = 8)\n",
    "# B.show_board()\n",
    "# print 'hi'\n",
    "# u = (1,2)\n",
    "# v = (2,3)\n",
    "# B.take_action((u,v))\n",
    "# B.show_board()\n",
    "\n",
    "# u = (4,5)\n",
    "# v = (5,4)\n",
    "\n",
    "# B.take_action((u,v))\n",
    "# B.show_board()\n",
    "\n",
    "\n",
    "# u = (2,1)\n",
    "# v = (1,2)\n",
    "\n",
    "# B.take_action((u,v))\n",
    "# B.show_board()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# u = (6,5)\n",
    "# v = (7,4)\n",
    "\n",
    "# B.take_action((u,v))\n",
    "# B.show_board()\n",
    "\n",
    "# u = (2,3)\n",
    "# v = (1,4)\n",
    "\n",
    "# B.take_action((u,v))\n",
    "# B.show_board()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print 'done!'\n",
    "\n",
    "\n",
    "# B.step_random()\n",
    "\n",
    "# B.show_board()\n",
    "# # u = (2,5)\n",
    "# # v = (0,3)\n",
    "\n",
    "# # B.take_action((u,v))\n",
    "# # B.show_board()\n",
    "\n",
    "# B.step_random()\n",
    "\n",
    "# B.show_board()\n",
    "\n",
    "# B.step_random()\n",
    "\n",
    "# B.show_board()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully random game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# B = checkers_state(board_size = 8)\n",
    "# B.show_board()\n",
    "\n",
    "# for i in range(100):\n",
    "#     print \"Move %d: Player %d\" % (i, B.player)\n",
    "#     B.step_random(inplace = True)\n",
    "#     B.show_board()\n",
    "#     if B.done:\n",
    "#         print 'done. Winner: Player ', B.winner()\n",
    "#         break\n",
    "    \n",
    "# #7080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game played using Monte-Carlo Tree Search algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 0 commencing.\n",
      "Player 0 wins! (after 49 moves)\n",
      "Game 1 commencing.\n",
      "Player 0 wins! (after 49 moves)\n",
      "Game 2 commencing.\n",
      "Player 1 wins! (after 49 moves)\n",
      "Game 3 commencing.\n",
      "Player 1 wins! (after 49 moves)\n",
      "Game 4 commencing.\n",
      "Player 0 wins! (after 49 moves)\n",
      "Game 5 commencing.\n",
      "Player 0 wins! (after 47 moves)\n",
      "Game 6 commencing.\n",
      "Player 0 wins! (after 29 moves)\n",
      "Game 7 commencing.\n",
      "Player 0 wins! (after 18 moves)\n",
      "Game 8 commencing.\n",
      "Player 0 wins! (after 17 moves)\n",
      "Game 9 commencing.\n",
      "Player 0 wins! (after 39 moves)\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "games_list = []\n",
    "winners_list = []\n",
    "all_game_trees_list = []\n",
    "max_turns = 50\n",
    "\n",
    "\n",
    "for game_num in range(10):\n",
    "\n",
    "\n",
    "    game = checkers_state(board_size = 6, max_turns = max_turns)\n",
    "    #game.show_board()\n",
    "\n",
    "    game_states_list = []\n",
    "    game_trees_list = []\n",
    "    print \"Game %d commencing.\" % game_num\n",
    "    for i in range(max_turns):\n",
    "\n",
    "        game.notes = ''\n",
    "        game.notes += 'Player %d now choosing action from board above.\\n' %  game.player\n",
    "        if game.player == 0:\n",
    "            game_tree = MonteCarloTree( deepcopy(game), \n",
    "                                       budget = 50, \n",
    "                                       num_simulations = 5, \n",
    "                                       endgame_predictor = None,\n",
    "                                       max_steps_to_simulate = 100,)\n",
    "            action = game_tree.UCTSearch()\n",
    "            game_trees_list.append(deepcopy(game_tree))\n",
    "            game.notes +=  'Size of tree: %d\\n' % len(game_tree.tree)\n",
    "\n",
    "            if action is None:\n",
    "                game.notes +=  \"No good move.  Taking random action.\\n\"\n",
    "                action = game.random_action()\n",
    "        else:\n",
    "            game_trees_list.append(None) #to keep indexing consistent\n",
    "#            game.notes += \"Dumb player 1 moving.  Taking random action.\\n\"\n",
    "#             action = game.random_action()\n",
    "            \n",
    "            game_tree = MonteCarloTree( deepcopy(game), \n",
    "                           budget = 50, \n",
    "                           num_simulations = 1, \n",
    "                           endgame_predictor = simple_checkers_predictor(),\n",
    "                           max_steps_to_simulate = 0)\n",
    "            action = game_tree.UCTSearch()\n",
    "            game_trees_list.append(deepcopy(game_tree))\n",
    "            game.notes +=  'Size of tree: %d\\n' % len(game_tree.tree)\n",
    "\n",
    "            if action is None:\n",
    "                game.notes +=  \"No good move.  Taking random action.\\n\"\n",
    "                action = game.random_action()\n",
    "        game_states_list.append(deepcopy(game))\n",
    "        (observation, reward, done, info) = game.step(action)        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if done:\n",
    "            print 'Player %d wins! (after %d moves)' % (game.winner(), i)\n",
    "            game.notes = 'Player %d wins! (after %d moves)' % (game.winner(), i)\n",
    "            \n",
    "            winners_list.append(game.winner())\n",
    "        #print game.notes\n",
    "        #game.show_board()\n",
    "        if done:\n",
    "            game_states_list.append(deepcopy(game))\n",
    "            break\n",
    "    else:\n",
    "        print \"Game timed out.\"\n",
    "        winners_list.append(None)\n",
    "        \n",
    "    games_list.append(deepcopy(game_states_list))\n",
    "    all_game_trees_list.append(game_trees_list)\n",
    "print winners_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********\n",
      "In epoch 0, with player 0 budget: 0, player 1 budget: 0\n",
      "Player 0 won 6/10 times.\n",
      "**********\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-26f5a03482f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mgame_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonteCarloTree\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_simulations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUCTSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mgame_trees_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotes\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0;34m'Size of tree: %d\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-3d53941e3f0f>\u001b[0m in \u001b[0;36mUCTSearch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mtotal_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_simulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mtotal_Q\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mnext_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_simulation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-3d53941e3f0f>\u001b[0m in \u001b[0;36mSimulate\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mnsteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m#ignore given reward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-d2f40c89b667>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, i, inplace)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_from_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-d2f40c89b667>\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(self, action, inplace)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_players\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_action_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mturn_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-d2f40c89b667>\u001b[0m in \u001b[0;36mupdate_action_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmove_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmove_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_legal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                     \u001b[0mpossible_moves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-d2f40c89b667>\u001b[0m in \u001b[0;36mis_legal\u001b[0;34m(self, action, explain)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "budgets_list = [0,10,50,200]\n",
    "\n",
    "games_list = []\n",
    "all_game_trees_list = []\n",
    "all_winners_list = []\n",
    "\n",
    "batch_size = 10\n",
    "max_turns = 50\n",
    "epoch_index = 0    \n",
    "\n",
    "\n",
    "for i in range(len(budgets_list)):\n",
    "    for j in range(i+1):\n",
    "        player_0_budget = budgets_list[i]\n",
    "        player_1_budget = budgets_list[j]\n",
    "\n",
    "        \n",
    "        #print \"Starting epoch %d\" % epoch_index\n",
    "        #print \"Player 0 budget: %d, player 1 budget: %d\" % (player_0_budget, player_1_budget)\n",
    "\n",
    "\n",
    "\n",
    "        winners_list = []\n",
    "\n",
    "\n",
    "        for game_num in range(batch_size):\n",
    "\n",
    "\n",
    "            game = checkers_state(board_size = 6, max_turns = max_turns)\n",
    "            #game.show_board()\n",
    "\n",
    "            game_states_list = []\n",
    "            game_trees_list = []\n",
    "            #print \"Game %d commencing.\" % game_num\n",
    "            for move_num in range(max_turns + 1):\n",
    "\n",
    "                game.notes = ''\n",
    "                game.notes += 'Player %d now choosing action from board above.\\n' %  game.player\n",
    "                if game.player == 0:\n",
    "                    budget = player_0_budget\n",
    "                else:\n",
    "                    budget = player_1_budget\n",
    "                    \n",
    "                game_tree = MonteCarloTree( deepcopy(game), budget = budget, num_simulations = 10)\n",
    "                action = game_tree.UCTSearch()\n",
    "                game_trees_list.append(deepcopy(game_tree))\n",
    "                game.notes +=  'Size of tree: %d\\n' % len(game_tree.tree)\n",
    "\n",
    "                if action is None:\n",
    "                    game.notes +=  \"No good move.  Taking random action.\\n\"\n",
    "                    action = game.random_action()\n",
    "                game_states_list.append(deepcopy(game))\n",
    "                (observation, reward, done, info) = game.step(action)        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if done:\n",
    "                    #print 'Player %d wins! (after %d moves)' % (game.winner(), i)\n",
    "                    winner = game.winner()\n",
    "                    game.notes = 'Player %d wins! (after %d moves)' % (game.winner(), i)\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "                #print game.notes\n",
    "                #game.show_board()\n",
    "                if done:\n",
    "                    game_states_list.append(deepcopy(game))\n",
    "                    break\n",
    "            else:\n",
    "                print \"Game timed out.\"\n",
    "                winner = None\n",
    "            \n",
    "            winners_list.append(winner)\n",
    "\n",
    "            winner_info = {'player_0_budget':player_0_budget,\n",
    "                           'player_1_budget':player_1_budget,\n",
    "                           'winner':winner}\n",
    "            all_winners_list.append(winner_info)\n",
    "            \n",
    "            \n",
    "            games_list.append(deepcopy(game_states_list))\n",
    "            all_game_trees_list.append(game_trees_list)\n",
    "\n",
    "        print \"\\n**********\"\n",
    "        print \"In epoch %d, with player 0 budget: %d, player 1 budget: %d\" % (epoch_index, player_0_budget, player_1_budget)\n",
    "        print \"Player 0 won %d/%d times.\" % (winners_list.count(0), len(winners_list))\n",
    "        print \"**********\\n\"\n",
    "        epoch_index += 1        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_winners_df = pd.DataFrame(all_winners_list)\n",
    "winner_matrix = all_winners_df.groupby(['player_0_budget', 'player_1_budget']).mean()\n",
    "#winner_matrix.rename(columns = {'winner':'pct_player_0_win'}, inplace = True)\n",
    "\n",
    "winner_matrix = refactor(winner_matrix, columns = ['player_1_budget'])\n",
    "winner_matrix = winner_matrix.rename(columns = {col:  col.replace('winner', 'pct p1 won, p1 budget') for col in winner_matrix.columns } )\n",
    "\n",
    "\n",
    "winner_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d6757fa8a6424383b55e21181b33f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game_to_view = 1\n",
    "game_states_list = games_list[game_to_view]\n",
    "\n",
    "def game_slider(i):\n",
    "    game_states_list[i].show_board()\n",
    "    print game_states_list[i].notes\n",
    "    #return 'Player: %d' % game_states_list[i].player\n",
    "\n",
    "interact(game_slider, i = IntSlider(min=0,max=len(game_states_list)-1,step=1,value=0)  )\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next goals:\n",
    "\n",
    "- implement kings. draws?\n",
    "- implement simple DNN to predict winner. Should determine more pieces -> better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGxdJREFUeJzt3Xt0VeWd//H3NzfIhYASFBCGSysX\n0VIh8EPBMiK6REWsl9XiEmcYK+BYdVqto7USmelyqlXbah1HWnD8VSqL5a3eCsUKI0iFJopVA/5Q\nxBGJBhQICbmePL8/noAohOyEs88+YX9ea51F9mHvk2/2Op/zPPvZz97HnHOISLxkRF2AiKSegi8S\nQwq+SAwp+CIxpOCLxJCCLxJDgYJvZj3M7Akz22hmG8zstLALE5HwZAVc71fAUufcpWaWA+SFWJOI\nhMzamsBjZt2B9cBgp9k+IkeFIC3+IGA78IiZjQTKgBucczUHrmRms4BZAPn5+aOHDRuW7FqPyKef\nfkoikYi6jC/p3bs3GRnpNcyi/RRcOu6rioqKHc65Xm2tF6TFLwZeA8Y759aa2a+AKufc7a1tU1xc\n7EpLS9tbc6jmzZsXdQkHKSkpibqEg2g/BZeO++qOO+4oc84Vt7VekI/RrcBW59zaluUngFFHUpyI\nRKvN4DvnPgE+MrOhLU+dBZSHWpWIhCroqP51wKKWEf3NwMzwShKRsAUKvnNuPdDmcYOIdA7pN1Qq\nIqFT8EViSMEXiSEFXySGgo7qSzrauxfKy2HPHsjPhyFDoEePqKtKP87Bpk3w6ad+uW9f+NrXoq0p\nYgp+Z1ReDr/6FTz2GGRlgZl/vr4eLrgAfvhDOE0XULJnj99H994LFRWQne2fb2iAAQPgppvgu9/1\nH5oxo65+Z+Ic/PSnUFwMCxf6Fr+qCnbv9o+6OnjqKZg8GWbOhMbGqCuOzltv+Vb9Rz+C99/3+2rf\nfqqthY0b4YYbfC/p3XejrjblFPzOZO5c+I//8G/cpqZDr9Pc7N/kS5bA9Ol+OW7Ky2H8eNi+HWpq\nWl+vpsb3BMaNg82bU1dfGlDwO4s1a+C++3yog9i7F5Yuhd/9Lty60o1zMHUqVFcHX7+qCr797XDr\nSjMKfmexr6Vvj5oaf2gQp9sorFgBlZXt+5ubm+G99yDNrigNk4LfGVRUwPLlHQtwRQX85S/Jryld\n/exnwVv7A9XVwV13Jb+eNKXgdwalpdClS8e2bWiIV/DXrm17nUNpbobVq5NbSxpT8DuDPXs63l1v\nbPTbx0VdXce3DTp+chRQ8DuDwkLo6K2ncnL89nGRm9vxbWN0Pl/B7wzGjPGTczoiKwsmTEhuPels\n/PgvJjS1R2YmnHlm8utJUwp+Z3D88TBlSsda/QEDYOzY5NeUrm65BfI6cPf3Ll3g5puTX0+aUvA7\ni1tvha5d27dNfj785Cfh1JOuJkyAfv3a9yGZmQnDh8PIkeHVlWYU/M5izBi4/fbgrVleHlx8sZ+9\nFydm8PzzflwjSJc/I8Nf2PT00+HXlkYU/M7kllvgzjv9AFZOzqHXycryof+nf4JHHunY8W5n9/Wv\nw2uvQZ8+UFDQ+noFBdC/vz9d2r9/6upLAwp+Z3PDDfD223Dddb5V69YNunf3/+bmwowZfnrvAw/4\nLmxcDR3qZ+P953/CN77hD5MKC/2jSxcYPRp+8xt/gc7AgVFXm3K6LLczGjwY7rnHt/7vv+/nmhcU\n+DdwjE5JtWnfB+GMGbB1q78e3wx69/bX5MeYgt+Z5eT4QSlpW79+/iGAuvoisaTgi8SQgi8SQwq+\nSAwp+CIxFGhU38y2AHuABNAU5Pu3RSR9ted03pnOuR2hVSIiKaOuvkgMBQ2+A/5kZmVmNivMgkQk\nfEGDP8E5NwqYAlxrZt/66gpmNsvMSs2stLKyMqlFJkN+Gk5lre7ITSFDpv0UXDruq6DMtfNebmZ2\nB1DtnLuntXX69u3rZs+efYSlJVdJSUnUJRxk3rx5UZdwEO2n4NJxX5lZWZDB9zZbfDPLN7Nu+34G\nzgHePvISRSQqQUb1jweeNn9ddxbwe+fc0lCrEpFQtRl859xmID73JBKJAZ3OE4khBV8khhR8kRhS\n8EViSMEXiZJzkEik/Ncq+CKptm0blJT4m35mZUF2tr8l+mWX+W827ugXpLaDbrYpkiqJhL89+oIF\nfvnAb/atrYWnnoI//hEGDYIXXwz1Xv9q8UVSIZGAiy7yX3JSV3for/NuboaaGtiwAU49FbZsCa0c\nBV8kFebNg5dfhr172143kYCdO/2394Z0/K/gi4StthZ+8Ytgod+nuRl27PBd/hAo+CJhW7y4Y9tV\nV8PPfpbcWloo+CJhW7TIh7gj1q499HjAEVLwRcK24whuVZmT44/3k0zBFwlbbm7Ht00kjmz7Vij4\nImEbPdpP0umI/Hz/1d5JpuCLhO366yEzs/3bde0K110HGcmPqYIvErYhQ6C4GPxdrNrnn/85+fWg\n4IukxoIF0K1b8PXz8uCuu+D440MpR8EXSYUhQ2DlSjj2WD9S3xozH/qSEn+IEBIFXyRVTj0V3nnH\nX6hTWOgfXbr4D4KCAn9MP2UKLFsGN98caim6Ok8klXr3hrvvhp/+1Ad8yxZoaICiIjj33NC69l+l\n4ItEIScHpk6N7Nerqy8SQwq+SAwp+CIxpOCLxJCCLxJDCr5IDAUOvpllmtkbZvZ8mAWJSPja0+Lf\nAGwIqxARSZ1AwTezfsD5wG/DLUdEUiFoi/9L4GagubUVzGyWmZWaWWltbW1Sikum6o7e8yxE+fn5\nUZdwEO2n4NJxXwXV5pRdM7sAqHTOlZnZ37e2nnNuPjAfoLi42JWUlCStyGSYN29e1CUcJN32EWg/\ntUc67quggrT444ELzWwLsBiYZGaPhVqViISqzeA75251zvVzzg0Evgu87Jy7IvTKRCQ0Oo8vEkPt\nuizXObcSWBlKJSKSMmrxRWJIwReJIQVfJIYUfJEYUvBFYkjBF4khBV8khhR8kRhS8EViSMEXiSEF\nXySGFHyRGFLwRWJIwReJIQVfJIYUfJEYUvBFYkjBF4khBV8khhR8kRhS8EViSMEXiSEFXySGFHyR\nGFLwRWJIwReJIQVfJIbaDL6ZdTWzdWb2ppm9Y2ad90vBRQQI9qWZ9cAk51y1mWUDq83sj86510Ku\nTURC0mbwnXMOqG5ZzG55uDCLEpFwBTrGN7NMM1sPVALLnXNrD7HOLDMrNbPSysrKZNd5xPLz86Mu\n4SDV1dVtr5Ri2k/BpeO+Csp8gx5wZbMewNPAdc65t1tbr2/fvm727NlJKC95SkpKoi7hIPPmpd9w\nifZTcOm4r8yszDlX3NZ67RrVd87tAlYA53a0MBGJXpBR/V4tLT1mlgucDWwMuzARCU+QUf0+wKNm\nlon/oFjinHs+3LJEJExBRvX/BpyaglpEJEWCtPgpV19fz549e2hubiY3N5eCggLMLOqyRI4aaRP8\niooKysrK+OCDD9i9ezeFhYVkZGRQU1ODmdGvXz9GjhzJsGHDyMzMjLpckU4t8uB//vnnvPDCC2zf\nvp3Ro0dz2WWX0atXr/3hds5RVVXFli1bWLduHcuWLWPKlCkMHz484spFOq9Ig//mm2+ydOlSJkyY\nwOWXX37IltzM6N69OyNHjmTkyJF8+OGHPPvss5SXlzNt2jSysiL/7BLpdCJLTWlpKatWrWLmzJkc\nd9xx+5+vq6ujvLycnTt3kkgkyM/PZ+jQoRQVFQEwYMAA5syZw9NPP83jjz/O9OnTFX7pfKqq4Ikn\n4IMPoK4OjjsOLrwQhg5Nya+PJDEffvghK1as4KqrruLYY48F4LPPPmPlypVs2LABM6OxsRGAjIwM\nVqxYQa9evZg4cSLDhg0jOzubSy65hCVLlrB8+XKmTJkSxZ8h0n7vvQd33AFPPgmZmVBT45/Pzoa5\nc2HECP/vhReGWkbKr8dvaGjgmWeeYerUqftDv2XLFh5++GHefvttmpqa9oceoLm5maamJioqKnjy\nySdZtmwZzjkyMzOZNm0a5eXlfPDBB6n+M0Ta75VXYNQoWLzYt/L7Qg/Q2OifKyuD6dPhppugHdPp\n2yvlwV+/fj3HHXccw4YNA/xo/qJFi2hoaKCt6wYaGxspLS1lxYoVAOTl5XHOOefsXxZJW2+8Aeed\nB3v2QCJx+HX37oWHHoIQrwVIafCdc6xbt45x48btf+7ZZ5/9UgvflsbGRtasWcPu3bsBOOmkk9i5\ncycVFRVJr1ckab73vS+38G3Zuxd+/nP46KNQyklp8Hft2kVdXR0DBw4E4JNPPmH79u3tfh3nHGvX\n+iuDMzMzOfnkk9m0aVMySxVJnr/9DTZsaP92zsEDDyS/HlIc/G3btnHCCSfsn4W3bt06Em11ew4h\nkUhQWlpKc3MzAH379mXbtm1JrVUkaR54ABoa2r9dfT38139By/s8mVIa/J07d9KzZ8/9y59++mmb\nx/WtSSQS1NfXA9CzZ0927tyZlBpFku6tt9o+rm9NfT20HNYmU0qD39zcTEbGF7+yI639PmZGU1MT\n4E/5dfQDRCR0LQ1Uh2RkHNn2rb1s0l/xMHJzc6k5YIDjSG5dlEgkyM3NBaCmpmb/zyJp5/jjO75t\nYyMcc0zyammR0uD36dPnS8fi3/zmN8nJyenQaw0cOHD/jL2Kigr69OmTlBpFku4f/gG6devYthMn\nQpcuya2HFAe/d+/e7Nq1i6qqKgCGDx/+pa5/UDk5OUyYMGH/8vvvv0///v2TVqdIUl1yiZ+l114F\nBXDrrcmvhxQHPysri1NOOYWysrL9y2eccQbZ2dmBXyMjI4MePXowePBgACorK9m+fTtDUzTHWaTd\ncnLgttsgLy/4NllZMHAgnHVWKCWlfObeuHHj+Otf/7q/1T/99NMZMWJEoPBnZmaSn5/PlVdeiZnh\nnOPPf/4zY8eO1YU6kt5uvBG+851g4c/J8eMCL70EId2AJuXBLyoqYuzYsfzhD3+gubkZM2PatGlM\nmDCBrKysQ34AZGRkkJWVRb9+/bjmmmsoKCgA/PTfXbt2cfrpp6f6zxBpHzNYsABuuQVyc+FQA9vZ\n2f7/Tj8d3nzzyAYF2xDJl2aeccYZJBIJnnvuuf3hnzhxIjfddBPnnHMORUVFdOnShezsbAoKCigu\nLmbOnDnMnDmTvJZPzHfffZeXXnqJiy++WK29dA5mcPvt8Mknfjru8OFQWOh7AX36wJw5sH49rFgB\nB8x3CUMkicnMzGT69OksXryYRYsWMXXqVHr06EHXrl0ZM2YMY8aMaXXbRCLB6tWrWbduHdOnT+f4\nED8VRUJRWAjXXOMfEYmsqezSpQtXXHEFq1evZv78+YwZM4ZRo0bRvXv3Q67f2NhIeXk5r776KoWF\nhVx99dX06NEjxVWLHB0i7SNnZmYyceJERowYwdq1a3nooYfo2bMnffr04ZhjjsHMqK2tpaKigo8/\n/pi+ffsyadIkhg4dqrvuihyBtDg4Lioq4vzzz+fss8+moqKCbdu2UVVVtf/22sXFxVx44YUUFhZG\nXarIUSEtgr9PTk4OAwYMYMCAAVGXInJUi2RUX0SipeCLxFCQb8vtb2YrzKzczN4xsxtSUZiIhCfI\nMX4TcKNz7nUz6waUmdly51x5yLWJSEjabPGdcxXOuddbft4DbABOCLswEQlPu47xzWwg/iuz1x7i\n/2aZWamZldbW1ianuiSqrq6OuoSDHMmNSMKi/RRcOu6roAKfzjOzAuBJ4F+cc1Vf/X/n3HxgPkBx\ncbErCfGe4B0xb968qEs4SLrtI9B+ao903FdBBWrxzSwbH/pFzrmnwi1JRMIWZFTfgAXABufcfeGX\nJCJhC9LijwdmAJPMbH3L47yQ6xKRELV5jO+cWw3oihiRo4hm7onEkIIvEkMKvkgMKfgiMaTgi8SQ\ngi8SQwq+SAwp+CIxpOCLxJCCLxJDCr5IDCn4IjGk4IvEkIIvEkMKvkgMKfgiMaTgi8SQgi8SQwq+\nSAwp+CIxpOCLxJCCLxJDCr5IDCn4IjGk4IvEkIIvEkMKvkgMBfm23IVmVmlmb6eiIBEJX5AW/7+B\nc0OuQ0RSqM3gO+deAT5PQS0ikiI6xheJoaQF38xmmVmpmZVWVlYm62WTJj8/P+oSDlJdXR11CQfR\nfgouHfdVUOaca3sls4HA8865k4O8aN++fd3s2bOPrLIkKykpibqEg8ybNy/qEg6i/RRcOu4rMytz\nzhW3tZ66+iIxFOR03uPAX4ChZrbVzK4KvywRCVNWWys456anohARSR119UViqM0WP/Z27oSXX4bX\nX4dNm6ChAQoKYMQIKC6GiRMhJyfqKkXaRS1+azZuhH/8Rxg0CB55BLKy4NvfhiuvhMmTYccOKCmB\nv/s7+PGP/QeESCehFv+rmprgrrvgF7+Am26C996DoqLW19+4Ee67D04+GR58EC66KHW1inSQgn+g\n+nr4znegqgrKymDAgC//f2Mj1Nb6rn5GS2dp2DCYPx9WrfK9gXffhX/919TXLp1SfX09DQ0NFBQU\nYGYp+73q6u/jnA9uZiYsXfpF6HfsgJ//HPr1gy5dfOufnQ2jR8Pjj/sPC4AzzoBXX4WFC+Ghh6L7\nOyTtbd68mRtvvJEePXqQl5fHscceS3Z2NlOmTGH58uU0NzeHXoOCv8+jj/pu++9/7wfrnIN774X+\n/f2x/Mcf++caG6G52Q/2zZoFvXvD//yPf42+feGFF+D22/1riRygsbGRmTNnMmLECH7961+ze/du\nmpubaWpqIpFIsHTpUi6++GJOPPFENm/eHGotCj7A7t3wox/B737nW3XwA3Zz50Jdne/eH0p1Neza\nBVOmwLJl/rmvfx3+7d/gmmtSU7t0Ck1NTZx33nksWbKEuro6GhoaDrledXU1W7ZsYfTo0WzatCm0\nehR88KP2kyfDN77hl595Bu6/H/buDbZ9bS1ccgls3eqXr77an/p7881w6pVO57bbbmPNmjXsDfCe\nam5uZvfu3UyaNImmpqZQ6lHwwQf/wBZ67tzgod+nqQkeeMD/nJ3tw//II8mrUTqtmpoaHnzwwUCh\n38c5x+7du3nuuedCqUnBr672p+xOO80vv/46vP9++1+nvt4P6tXV+eUzz4TXXktendJpPfbYYx0a\nsd+zZw933nlnCBUp+PDWW3DSSb6VBnjxxS9G6tvLzJ8GBBg1ynf1A1z2LEe3JUuWdPieAm+88Qa1\nrY0xHQEFv6oKjjnmi+XKSkgkOv56+2bwFRT412llEEfi47PPPuvwtjk5OezatSuJ1XgKfnb2l8PZ\nrVvHX8sM8vL8z4mEf+zrSUhs5e17T3RAIpE4ou1bo+APGQLl5V90yUeO9K11R9TV+Zl84M/jDx78\nxQw/ia2xY8eS3cEGoFu3bhQWFia5IgUfTjjBz9bbssUvX3SRX24vM5g0yU/iAVi71l+9J7F3/fXX\nk9mB91Rubi4/+MEPQpnKq+Cb+bA/+qhfzsmB738funZt3+vk5X15jv6jj/qr+ST2Bg8ezLhx48ho\nZ+/POUdY965U8MEH/eGH/ak9gFtu8ZfjBu2e5eX5i3u+9S2/XFrqTwkq+NJi4cKFdO/ePXDrnZeX\nx/3330/R4a4MPQIKPvibapx7rr8MF/wx/iuv+OfbGljJz4fLL/dX6Jn5U4EzZ8Kdd2pgT/YbNGgQ\nq1atolevXnQ9TG8yIyOD3Nxc7r77bq6++urQ6lHw9/nlL/1VeY895peLivwEnHvv9fPv8/P9B0LX\nrl/8O3EiLFkCv/mNHxdwzvceTjwRZsyI9u+RtDNixAjKy8u59dZbKSoqolu3buTl5ZGbm0u3bt3o\n2rUrl156KatWreLaa68NtRZdj79P9+5+8s7kyb7LP3u2v2Bnzhz/c1kZvPOOn8pbWAgTJnz5ev26\nOrj2Wn+G4E9/8q2/yFf07NmTuXPnctttt7Fy5Uo+/PBDGhoa6NmzJ5MnT+aYA+eUhEjBP9BJJ8HK\nlXDppfDcc/6OOgMH+hAXF7c+Sv/KK/4S3VNOgeXLO346UGIjMzOTs846K7Lfr+B/1ZAhfnDu7rv9\nzTbGj4fp033ov/Y1f16+ocG3/mvW+AtxPvsM7rnHX6En0gnoGP9QcnLgJz+B//1fmDbNH8effbbv\n+ufl+RZ9xgxYtw7+/d/9RT4KvXQiavEPJz8frrrKP8C39I2N/gMgS7tOOi+9e9sjJ0f30Jejgrr6\nIjGk4IvEUKDgm9m5Zvaumb1nZreEXZSIhCvI12RnAg8CU4CTgOlmdlLYhYlIeIK0+GOB95xzm51z\nDcBiYFq4ZYlImMy1cU84M7sUONc5972W5RnA/3HOff8r680CZrUsngy8nfxyj0gRsCPqIr5CNQWT\njjVBetY11DnX5m2kknY6zzk3H5gPYGalzrm0uguFagpGNQWXjnWZWWmQ9YJ09T8G+h+w3K/lORHp\npIIE/6/AiWY2yMxygO8Cz4ZbloiEqc2uvnOuycy+DywDMoGFzrl32thsfjKKSzLVFIxqCi4d6wpU\nU5uDeyJy9NHMPZEYUvBFYiipwU/Hqb1mttDMKs0sbeYVmFl/M1thZuVm9o6Z3ZAGNXU1s3Vm9mZL\nTfOirmkfM8s0szfM7PmoawEwsy1m9paZrQ96+ixsZtbDzJ4ws41mtsHMTjvs+sk6xm+Z2vv/gLOB\nrfizAdOdc+VJ+QUdr+tbQDXwf51zJ0dZyz5m1gfo45x73cy6AWXARVHuK/P3fc53zlWbWTawGrjB\nORf5V/6a2Q+BYqDQOXdBGtSzBSh2zqXN5B0zexRY5Zz7bcvZtzznXKtfupfMFj8tp/Y6514BPo+6\njgM55yqcc6+3/LwH2ACcEHFNzjm37ytds1sekY/8mlk/4Hzgt1HXkq7MrDvwLWABgHOu4XChh+QG\n/wTgowOWtxLxm7kzMLOBwKnA2mgr2d+lXg9UAsudc5HXBPwSuBlojrqQAzjgT2ZW1jJVPWqDgO3A\nIy2HRL81s/zDbaDBvQiZWQHwJPAvzrmqqOtxziWcc9/Ez84ca2aRHhqZ2QVApXOuLMo6DmGCc24U\n/orVa1sOJ6OUBYwCHnLOnQrUAIcdY0tm8DW1tx1ajqOfBBY5556Kup4DtXQTVwDnRlzKeODClmPq\nxcAkM3ss2pLAOfdxy7+VwNP4w9wobQW2HtBDewL/QdCqZAZfU3sDahlIWwBscM7dF3U9AGbWy8x6\ntPycix+k3RhlTc65W51z/ZxzA/Hvp5edc1dEWZOZ5bcMyNLSnT6HiK9Edc59AnxkZkNbnjoLOOxA\ncTKvzuvI1N7QmdnjwN8DRWa2FShxzi2ItirGAzOAt1qOqQF+7Jx7McKa+gCPtpydyQCWOOfS4vRZ\nmjkeeLrlyy+zgN8755ZGWxIA1wGLWhrdzcDMw62sKbsiMaTBPZEYUvBFYkjBF4khBV8khhR8kRhS\n8EViSMEXiaH/D/cvFBKXxamjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "self = game\n",
    "#plt.clf()\n",
    "rcParams['figure.figsize'] = 4,4\n",
    "#fig, ax = plt.subplots() # note we must use plt.subplots, not plt.subplot\n",
    "# (or if you have an existing figure)\n",
    "# fig = plt.gcf()\n",
    "# ax = fig.gca()\n",
    "\n",
    "#ax.add_artist(circle2)\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "#ax.add_artist(plt.Circle( (i + .5, j + .5), 0.2, color='blue'))\n",
    "\n",
    "for i in range(self.board_size):\n",
    "    for j in range(self.board_size):\n",
    "        if (i + j) % 2 == 0:\n",
    "            square_color = 'grey'\n",
    "        else:\n",
    "            square_color = 'white'\n",
    "\n",
    "        ax.add_artist(plt.Rectangle( (i, j), 1,1, color=square_color))\n",
    "        if self.board[i,j] > 0:\n",
    "            color = 'red'\n",
    "        elif self.board[i,j] < 0:\n",
    "            color = 'black'\n",
    "        else:\n",
    "            continue\n",
    "        #print i,j\n",
    "        ax.add_artist(plt.Circle( (i + .5, j + .5), 0.2, color=color))\n",
    "        if abs(self.board[i,j]) > 1:\n",
    "            ###This piece is a king\n",
    "            ax.add_artist(plt.Circle( (i + .5, j + .5), 0.3, color=color, fill = False))\n",
    "\n",
    "plt.xlim(0,self.board_size)\n",
    "plt.ylim(0,self.board_size)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
